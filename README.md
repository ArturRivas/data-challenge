# Technical Challenge - Plataforma de datos


> **Objetivo:** DiseÃ±ar plataforma de datos end-to-end para una plataforma digital con usuarios activos a escala: desde la captura de eventos y cambios de estado, hasta los pipelines que alimentan analÃ­tica, modelos y sistemas en producciÃ³n, con foco en calidad, escalabilidad y confiabilidad.
---

## 1. IntroducciÃ³n

Esta propuesta describe una arquitectura end-to-end para capturar y procesar:

- **Eventos de comportamiento** (sesiones, interacciones, progreso, evaluaciones)
- **Cambios de estado** (suscripciÃ³n, completado, avance consolidado, etc.)
- Flujos **batch** y **streaming** para habilitar:
  - AnalÃ­tica (BI / Product Analytics)
  - Modelos de recomendaciÃ³n y personalizaciÃ³n
  - ExperimentaciÃ³n (A/B testing) y mÃ©tricas de aprendizaje
  - Casos de uso operativos en near real-time

**Principios de diseÃ±o**
- **Confiabilidad primero**: datos correctos y trazables > velocidad
- **Streaming donde aporta valor**: real-time solo para casos que lo requieren
- **Reproducibilidad**: datasets de analÃ­tica y ML deben reconstruirse
- **Cost-aware by design**: particionado, retenciÃ³n y backfills controlados
- **Data as a Product**: ownership, contratos y SLAs por dataset

---

## 2. Supuestos

Los siguientes supuestos guÃ­an las decisiones de arquitectura:

- Producto digital con **usuarios activos a escala** y **alto volumen de eventos**
- Se requieren distintos niveles de latencia:
  - **PersonalizaciÃ³n en tiempo real**: segundos
  - **AnalÃ­tica near real-time**: minutos
  - **Modelos batch**: diario/semanal + backfills
- Los consumidores de datos incluyen:
  - Producto / BI / Analytics Engineering
  - ML/AI (recomendaciones, personalizaciÃ³n, LLMs)
  - Operaciones (dashboards y alertas)
- Se necesita soporte para:
  - **evoluciÃ³n de esquemas**
  - **idempotencia y deduplicaciÃ³n**
  - **reintentos y recuperaciÃ³n**
  - **reprocesos/backfills**
  - **seguridad y PII** (RBAC / masking)

---

## 3. Arquitectura a Alto Nivel

### 3.1 Principales componentes

A continuaciÃ³n se muestra una visiÃ³n general de la plataforma (GCP):

![Diagram](/docs/diagrams/dataplatform_hla.svg)

**Productores**
- Web / Mobile (SDK de eventos)
- Backend services (eventos server-side)
- Sistemas operativos (pagos, suscripciones, evaluaciones)

**Ingesta**
- **Pub/Sub** como backbone de eventos (event-driven)
- **CDC** para cambios de estado desde sistemas transaccionales (cuando aplique)
- **DataFlow Batch** Cuando en costo beneficio de mas valor que el CDC y la latencia no sea un problema

**Procesamiento**
- **Streaming (near real-time):** Dataflow (Apache Beam)
- **Batch (ELT/ETL):** dbt + BigQuery

**OrquestaciÃ³n**
- **Composer (Airflow)**: para orquestaciÃ³n de process batch

**Almacenamiento**
- **Raw inmutable (Bronze):** GCS (Parquet) para auditorÃ­a y reprocesos
- **Curado (Silver/Gold):** BigQuery para modelos analÃ­ticos y marts
- (Opcional) snapshots/exports para datasets de ML en GCS

**Serving / Real-time**
- Store de baja latencia para features y agregados:
  - **Bigtable** o **Memorystore (Redis)** segÃºn el patrÃ³n de lectura/escritura
- API/servicio de personalizaciÃ³n consume features online

**Consumo**
- BI (Looker/Metabase)
- Producto (mÃ©tricas near real-time, segmentaciÃ³n)
- ML/AI (training datasets reproducibles + features)

---

### 3.2 Decisiones clave y trade-offs (alto nivel)

A continuaciÃ³n, las decisiones mÃ¡s relevantes con sus trade-offs y mitigaciones:

1) **Backbone event-driven con Pub/Sub**
- **Por quÃ©:** desacopla productores/consumidores, escalable y managed
- **Trade-off:** delivery at-least-once â†’ posibles duplicados
- **MitigaciÃ³n:** `event_id` + dedupe downstream + escrituras idempotentes

2) **SeparaciÃ³n explÃ­cita entre streaming y batch**
- **Por quÃ©:** optimiza costo/operaciÃ³n y alinea latencia con el caso de uso
- **Trade-off:** arquitectura hÃ­brida = mÃ¡s componentes
- **MitigaciÃ³n:** estÃ¡ndares de diseÃ±o + componentes reutilizables + observabilidad unificada

3) **Raw inmutable en object storage (GCS)**
- **Por quÃ©:** auditorÃ­a, trazabilidad y backfills baratos
- **Trade-off:** gestiÃ³n de lifecycle + doble storage (raw + curado)
- **MitigaciÃ³n:** polÃ­ticas de retenciÃ³n, compresiÃ³n y tiering

4) **BigQuery como core para analÃ­tica (Silver/Gold)**
- **Por quÃ©:** velocidad de entrega, performance analÃ­tica, menor carga operativa
- **Trade-off:** costo si no se optimizan consultas/modelos
- **MitigaciÃ³n:** particionado, clustering, incremental models (dbt), budgets/alerts

5) **Exactly-once â€œefectivoâ€ en lugar de exactly-once absoluto**
- **Por quÃ©:** en sistemas distribuidos, el exactly-once end-to-end es costoso y complejo
- **Trade-off:** requiere diseÃ±o explÃ­cito de idempotencia
- **MitigaciÃ³n:** claves determinÃ­sticas, dedupe, checkpoints y replays controlados

6) **Feature Store Lite en fase inicial**
- **Por quÃ©:** acelera time-to-value para personalizaciÃ³n
- **Trade-off:** menos automatizaciÃ³n que un feature store completo
- **MitigaciÃ³n:** definiciones de features en cÃ³digo + evoluciÃ³n a Vertex AI Feature Store

7) **Data Quality y SLAs desde el inicio (MVP)**
- **Por quÃ©:** evita pÃ©rdida de confianza y re-trabajo
- **Trade-off:** mÃ¡s esfuerzo inicial vs â€œsolo mover datosâ€
- **MitigaciÃ³n:** empezar con checks crÃ­ticos (freshness/volumen/duplicados) e iterar

---

## 4 Ãndice (detalle de diseÃ±o)

La documentaciÃ³n detallada se encuentra en la carpeta [`/docs`](./docs):

- ðŸ“„ **Arquitectura end-to-end (Capa de Datos + Flujo batch + Flujo streaming)**
  - [`docs/arquitecture.md`](./docs/architecture.md)

- âœ… **Confiabilidad: Data Quality, Gobierno, Seguridad y Monitoreo**
  - [`docs/data_quality_governance.md`](./docs/reliability_governance.md)

- ðŸ§° **Marco de desarrollo (estÃ¡ndares + CI/CD + Arquetipos)**
  - [`docs/data_development_framework.md`](./docs/framework.md)

- ðŸ—ºï¸ **Roadmap por fases**
  - [`docs/roadmap.md`](./docs/roadmap.md)

---

### Alternativa multi-cloud (AWS)

Si se requiere una implementaciÃ³n equivalente en AWS, el mapeo por capacidades serÃ­a:

- Pub/Sub â†’ Kinesis / MSK (Kafka)
- Dataflow â†’ Flink / Glue / EMR Spark
- GCS â†’ S3
- BigQuery â†’ Redshift / Snowflake
- Bigtable â†’ DynamoDB
- Memorystore â†’ ElastiCache (Redis)
- Airflow â†’ MWAA

> Nota: la arquitectura se mantiene; cambian los servicios managed.

---
