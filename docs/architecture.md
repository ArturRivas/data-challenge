# Arquitectura de Datos (Medallion + Lambda)

> **Objetivo:** habilitar anal√≠tica de producto, decisiones operativas y personalizaci√≥n en tiempo real con datos **confiables**, **reproducibles** y **operables** a escala.

> ‚ÑπÔ∏è **Alcance:** este documento define la arquitectura y decisiones principales (no es un dise√±o exhaustivo por componente). El foco es establecer un dise√±o claro, escalable y pragm√°tico.

---

## Arquitectura

![Diagram](/docs/diagrams/dataplatform_hla.svg)

---

## 1. Justificaci√≥n de patrones de dise√±o

### 1.1 Medallion (almacenamiento): Bronze ‚Üí Silver ‚Üí Gold

**Por qu√©:** separa responsabilidades y evita que el sistema se convierta en un ‚Äúwarehouse monol√≠tico‚Äù sin control.

- **Bronze:** historial crudo, auditabilidad, replay
- **Silver:** normalizaci√≥n por dominio, base reutilizable
- **Gold:** productos listos para consumo (BI/ML/product analytics)

**Trade-offs**
- (+) mejor trazabilidad, backfills y control de calidad
- (-) m√°s pasos (pero con ownership claro se vuelve un acelerador, no un freno)

---

### 1.2 Lambda (procesamiento): Batch + Streaming

**Por qu√©:** el producto necesita simult√°neamente:
- **Batch:** eficiencia, consistencia y reproducibilidad (reporting + ML offline)
- **Streaming:** baja latencia (personalizaci√≥n y se√±ales online)

**Trade-offs**
- (+) separa ‚Äúhot path‚Äù del ‚Äúcold path‚Äù (menos riesgo operacional)
- (-) requiere claridad en el source of truth (normalmente Silver/Gold)

---

## 2. Capas de datos (Medallion)

> Principio: cada capa tiene **prop√≥sito**, **consumidores** y **reglas m√≠nimas**.

---

### 2.1 Bronze / Raw (GCS)

**Objetivo**
- preservar datos tal como llegan (inmutables)
- habilitar replay/backfills
- desacoplar ingesti√≥n del warehouse

**Tecnolog√≠a**
- **GCS** (raw principal)

**Caracter√≠sticas**
- inmutable (append-only)
- particionado por fecha de evento/ingesta
- formato recomendado: **Parquet** (batch) / **Avro** (CDC) / JSON (si aplica)

**Organizaci√≥n recomendada**
- por **fuente** y **tipo de ingesta**
  - `raw/events/...`
  - `raw/cdc/...`
  - `raw/external/...`

**Modelado**
- ninguno (data-as-received + metadata m√≠nima)

**Trade-off**
- raw en GCS no es para consumo directo, es para **resiliencia + costo**.

---

### 2.2 Silver / Curated (BigQuery)

**Objetivo**
- estandarizar, deduplicar y normalizar
- crear entidades consistentes por dominio (reutilizables)

**Tecnolog√≠a**
- **BigQuery** como capa curada principal

**Caracter√≠sticas**
- schema estable
- reglas de negocio m√≠nimas
- idempotencia y dedupe por llaves (`event_id`, `session_id`, etc.)
- incremental por partici√≥n

**Organizaci√≥n**
- Dataset por **dominio de informaci√≥n**
  - `silver_identity`
  - `silver_learning`
  - `silver_product`
  - `silver_billing`

**Modelado**
- entidades normalizadas / snapshots
- SCD Type 2 cuando se requiere historial de estado

---

### 2.3 Gold / Data Products (BigQuery)

**Objetivo**
- exponer datasets listos para consumo (BI, producto, ML offline)
- estandarizar m√©tricas y definiciones

**Tecnolog√≠a**
- **BigQuery** (marts y capa sem√°ntica)

**Caracter√≠sticas**
- datasets documentados, estables y optimizados
- SLAs solo para productos cr√≠ticos (no para todo)

**Organizaci√≥n**
- por **producto de datos / iniciativa**
  - `gold.product_usage_daily`
  - `gold.learning_funnel`
  - `gold.recommendations_metrics`
  - `gold.ab_testing_results`

**Modelado**
- star schema / tablas wide / agregados (seg√∫n consumidor)

**Trade-off**
- si Gold crece sin ownership se duplica la l√≥gica ‚Üí por eso se organiza por ‚Äúproducto de datos‚Äù.

---

### 2.4 Serving / Online Layer (fuera de Medallion)

**Objetivo**
- habilitar lecturas low-latency para personalizaci√≥n en producci√≥n

**Tecnolog√≠a**
- **Bigtable** como Online Store

**Qu√© guarda**
- estado actual por usuario/sesi√≥n
- features online (√∫ltimas se√±ales)
- contadores y afinidades

üìå **Nota:** Bigtable no es ‚ÄúGold‚Äù. Es ‚Äúserving operational‚Äù.

---

## 3. Flujos Batch

> Batch prioriza **consistencia, reproducibilidad y costo**.

---

### 3.1 Batch T-1 (latencia diaria / horas)

**Cu√°ndo aplica**
- reporting
- m√©tricas de producto
- cohortes y funnels
- datasets de entrenamiento offline

**Dise√±o**
- **Composer (Airflow)** orquesta:
  - carga incremental a staging (si aplica)
  - `dbt run` (Silver ‚Üí Gold)
  - `dbt test` como gate

**Trade-offs**
- (+) barato, estable, reproducible
- (-) no resuelve personalizaci√≥n inmediata

---

### 3.2 Batch para completar CDC (latencia baja aceptable)

**Cu√°ndo aplica**
- cambios de entidades (suscripciones, progreso, perfiles)
- anal√≠tica operativa que tolera minutos

**Dise√±o**
- **Datastream ‚Üí GCS (CDC logs)**
- Composer ejecuta micro-batches (cada 5/15 min):
  - carga incremental a BigQuery staging
  - dbt incremental para ‚Äúcurrent + history‚Äù

**Trade-offs**
- (+) operaci√≥n m√°s simple que streaming full
- (+) hist√≥rico raw auditable
- (-) no es sub-segundo

---

### 3.3 Batch para backfills / reprocesos

**Cu√°ndo aplica**
- bugs de l√≥gica
- cambios de negocio
- reconstrucci√≥n hist√≥rica

**Dise√±o**
- replay desde Bronze (GCS)
- publicaci√≥n controlada (shadow + swap)

**Trade-offs**
- (+) resiliencia fuerte
- (-) requiere guardrails para no disparar costos

---

## 4. Flujos Streaming & Real-Time

> Streaming se usa solo cuando agrega valor claro (latencia y estado online).

---

### 4.1 Micro-batch con Dataflow (ventanas)

**Cu√°ndo aplica**
- agregaciones por ventana (1m/5m)
- m√©tricas near-real-time
- se√±ales que no requieren evento inmediato

**Dise√±o**
- Pub/Sub ‚Üí Dataflow (windowing) ‚Üí BigQuery/Bigtable

**Trade-offs**
- (+) buen balance costo/latencia
- (-) agrega delay por ventana

---

### 4.2 Event-by-event con Dataflow (hot path)

**Cu√°ndo aplica**
- features online sensibles al tiempo
- actualizaci√≥n inmediata de estado (ej. ‚Äú√∫ltima actividad‚Äù, contadores)

**Dise√±o**
- Pub/Sub ‚Üí Dataflow ‚Üí Bigtable (upsert por clave)
- idempotencia por `event_id` y dedupe strategy

**Trade-offs**
- (+) escalable y low-latency
- (-) m√°s costoso y exige disciplina de deduplicaci√≥n

---

### 4.3 Event-by-event con Cloud Run (consumers simples)

**Cu√°ndo aplica**
- transformaciones ligeras
- integraciones r√°pidas
- volumen moderado

**Dise√±o**
- Pub/Sub ‚Üí Cloud Run ‚Üí Bigtable / APIs / logs

**Trade-offs**
- (+) simple, r√°pido, mantenible
- (-) no ideal para procesamiento pesado o windowing

---

## 5 Integraci√≥n con ML / Anal√≠tica avanzada

### 5.1 Estrategia m√≠nima (pragm√°tica)

Separar claramente:
- **Offline ML:** entrenamiento con Silver/Gold (BigQuery)
- **Online ML:** inferencia en request-time con features online (Bigtable)

---

### 5.2 Datasets reproducibles de entrenamiento (offline)

**Fuente**
- Silver/Gold en BigQuery

**Recomendaci√≥n m√≠nima**
- versionar transformaciones (dbt git SHA)
- snapshot por ventana temporal (train/val/test)
- registrar metadata del dataset (fecha, query, feature set)

---

### 5.3 Feature Store (offline + online)

**Objetivo**
- consistencia entre entrenamiento e inferencia

**Propuesta**
- **Offline features:** BigQuery
- **Online features/state:** Bigtable

**Trade-offs**
- (+) escalable y claro por prop√≥sito
- (-) requiere ownership y definici√≥n m√≠nima de features

---

### 5.4 Inferencia en tiempo real (serving)

**Cu√°ndo ocurre**
- cuando el usuario solicita una decisi√≥n (home, ‚Äúsiguiente lecci√≥n‚Äù, recomendaciones)

**Dise√±o recomendado**
- App ‚Üí **Cloud Run (Personalization API)**
  - lookup de features en Bigtable
  - llamada al modelo en **Vertex AI Endpoint**
  - reglas de negocio + fallback
  - respuesta al usuario

üìå **Nota:** evitar que el pipeline streaming sea el path cr√≠tico de inferencia (reduce fragilidad y costo).

---

## 6. Decisiones clave (resumen ejecutivo)

- Medallion para separar raw/curated/products y habilitar replay + gobernanza
- Lambda para balancear costo/consistencia (batch) y latencia (streaming)
- GCS como raw principal (hist√≥rico + bajo costo)
- BigQuery como Silver/Gold (transformaci√≥n + anal√≠tica)
- Bigtable como Online Store (serving low-latency)
- Cloud Run + Vertex AI para inferencia real-time (request-driven)

---

## 7. Qu√© NO har√≠a en etapa inicial

- Feature store enterprise complejo sin casos productivos claros
- Inferencia en Dataflow como path cr√≠tico (alto costo y riesgo)
- Gold sin ownership (m√©tricas duplicadas y marts inconsistentes)
- Lineage manual perfecto desde d√≠a 1 (priorizar automatizaci√≥n)

---

## 8. Stack propuesto (servicios / herramientas)

> Principio: usar **lo m√≠nimo necesario**, priorizando herramientas administradas, reproducibles y con buena operabilidad.

| Componente | Servicio / Herramienta | Rol en la arquitectura | Justificaci√≥n breve |
|---|---|---|---|
| Data Lake (Raw/Bronze) | **GCS** | Almacenamiento hist√≥rico crudo e inmutable | Bajo costo, escalable, ideal para replay/backfills y auditor√≠a. |
| Data Warehouse (Silver/Gold) | **BigQuery** | Curaci√≥n, modelado, serving anal√≠tico | Motor serverless, r√°pido para ELT, integra bien con dbt y BI. |
| Transformaciones | **dbt** | ELT, tests, documentaci√≥n, incremental models | Acelera desarrollo con est√°ndares, CI/CD, modularidad y data quality gates. |
| Orquestaci√≥n Batch | **Composer (Airflow)** | Scheduling, dependencias, retries | Patr√≥n est√°ndar, control de ejecuci√≥n y observabilidad de pipelines batch. |
| CDC (Change Data Capture) | **Datastream** | Captura cambios desde BD transaccionales | Minimiza impacto en origen, habilita replicaci√≥n y sincronizaci√≥n continua. |
| Event Bus | **Pub/Sub** | Transporte de eventos en tiempo real | Desacopla productores/consumidores, escala alto volumen con baja fricci√≥n. |
| Stream Processing | **Dataflow** | Enriquecimiento streaming, windowing, stateful processing | Escalable, robusto para streaming real, soporta exactly-once seg√∫n dise√±o. |
| Serving low-latency | **Bigtable** | Estado online, contadores, features online | Baja latencia, alto throughput, ideal para ‚Äúkey-value access patterns‚Äù. |
| APIs / Consumers ligeros | **Cloud Run** | Consumo simple de eventos y serving API | Serverless, simple de operar, despliegue r√°pido, buen fit para microservicios. |
| Model Serving | **Vertex AI Endpoint** | Inferencia en tiempo real administrada | Facilita despliegue/operaci√≥n de modelos, autoscaling, versionamiento. |
| Observabilidad (m√≠nimo) | **Cloud Logging/Monitoring** | Logs, m√©tricas, alertas | Base operativa para SRE, troubleshooting y SLAs. |
| Gobierno (m√≠nimo) | **IAM + Data Catalog/Dataplex (opcional)** | Accesos, clasificaci√≥n, ownership | Control de acceso y base para gobierno sin sobredise√±ar al inicio. |

---

## 9. Equivalencias GCP ‚Üî AWS (alternativa)

| Necesidad | GCP (propuesta) | AWS (alternativa) |
|---|---|---|
| Event bus | Pub/Sub | Kinesis / MSK |
| Stream processing | Dataflow | Kinesis Data Analytics / Flink / Glue Streaming |
| Raw data lake | GCS | S3 |
| Warehouse | BigQuery | Redshift / Athena + Iceberg |
| Orquestaci√≥n batch | Composer (Airflow) | MWAA (Airflow) |
| Online store | Bigtable | DynamoDB |
| Serving API | Cloud Run | ECS Fargate / Lambda |
| Model serving | Vertex AI Endpoint | SageMaker Endpoint |
